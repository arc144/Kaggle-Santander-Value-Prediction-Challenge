{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56f3c3499260fe04c9d0c6535f59ea3320b8c987",
    "collapsed": true
   },
   "source": [
    "> Please go through Giba's post and kernel  to underrstand what this leak is all about\n",
    "> https://www.kaggle.com/titericz/the-property-by-giba (kernel)\n",
    "> https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post)\n",
    "> \n",
    "> Also, go through this Jiazhen's kernel which finds more columns to exploit leak\n",
    "> https://www.kaggle.com/johnfarrell/giba-s-property-extended-result\n",
    "> \n",
    "> I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field.\n",
    "> \n",
    "> **Let the competition begin! :D**\n",
    "\n",
    "### Just some small modifications from [original baseline](https://www.kaggle.com/tezdhar/breaking-lb-fresh-start)~\n",
    "- The leak rows are calculated separately on train/test set\n",
    "- Calculated the leaky values, correctness, for each lag\n",
    "- Hope this can help to do some *lag_selection*\n",
    "\n",
    "### Update leak process codes to Dmitry Frumkin's *fast* [version](https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2)\n",
    "- The result of Dmitry's original function and result of Hasan's function seem slightly different\n",
    "- Modified to make the output consistent with Hasan's function (Seems better score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "dc37a766646b5993cef0bc87ad6882728dd20cb2"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "transact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\n",
    "y = np.log1p(train[\"target\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9951f375af0d5a753031352e04a85a5a12a93e18"
   },
   "outputs": [],
   "source": [
    "test[\"target\"] = train[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6dcfc4df1340c38bfeac43fd4d19ba2763b3b916"
   },
   "source": [
    "We take time series columns from [here](https://www.kaggle.com/johnfarrell/giba-s-property-extended-result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', \n",
    "        'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', \n",
    "        '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867', \n",
    "        'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', \n",
    "        '1931ccfdd', '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', \n",
    "        '6619d81fc', '1db387535', \n",
    "        'fc99f9426',\n",
    "        '91f701ba2', '0572565c2', '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98'\n",
    "       ]\n",
    "\n",
    "# cols = ['f3cf9341c','fa11da6df','d47c58fe2','555f18bd3','134ac90df','716e7d74d','1bf8c2597',\n",
    "#                '1f6b2bafa','174edf08a','5bc7ab64f','a61aa00b0','b2e82c050','26417dec4',\n",
    "#                '51707c671','e8d9394a0','cbbc9c431','6b119d8ce','f296082ec','be2e15279',\n",
    "#                '698d05d29','38e6f8d32','93ca30057','7af000ac2','1fd0a1f2a','41bc25fef',\n",
    "#                '0df1d7b9a','2b2b5187e','bf59c51c3','cfe749e26','ad207f7bb','11114a47a',\n",
    "#                'a8dd5cea5','b88e5de84']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "2664b88d70c76fde0df57ca6f22f75997f72cb00"
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2\n",
    "def _get_leak(df, cols, lag=0):\n",
    "    d1 = df[cols[:-lag-2]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2 = df[cols[lag+2:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2['pred'] = df[cols[lag]]\n",
    "    #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n",
    "    d3 = d2[~d2.duplicated(['key'], keep=False)]\n",
    "    return d1.merge(d3, how='left', on='key').pred.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "d61c75092518f50a879e9e3d5883ab752f73912b"
   },
   "outputs": [],
   "source": [
    "def compiled_leak_result():\n",
    "    \n",
    "    max_nlags = len(cols) - 2\n",
    "    train_leak = train[[\"ID\", \"target\"] + cols]\n",
    "    train_leak[\"compiled_leak\"] = 0\n",
    "    train_leak[\"nonzero_mean\"] = train[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        train_leak[c] = _get_leak(train_leak, cols, i)\n",
    "        \n",
    "        leaky_cols.append(c)\n",
    "        train_leak = train.join(\n",
    "            train_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )[[\"ID\", \"target\"] + cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]\n",
    "        zeroleak = train_leak[\"compiled_leak\"]==0\n",
    "        train_leak.loc[zeroleak, \"compiled_leak\"] = train_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(train_leak[\"compiled_leak\"] > 0))\n",
    "        _correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in train\", leaky_value_counts[-1])\n",
    "        print(\n",
    "            \"% of correct leaks values in train \", \n",
    "            leaky_value_corrects[-1]\n",
    "        )\n",
    "        tmp = train_leak.copy()\n",
    "        tmp.loc[zeroleak, \"compiled_leak\"] = train_leak[\"nonzero_mean\"]\n",
    "        scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        print(\n",
    "            'Score (filled with nonzero mean)', \n",
    "            scores[-1]\n",
    "        )\n",
    "    result = dict(\n",
    "        score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return train_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "68f3fde6e5e9d274a4de6ef0975bbb4b682d5e85",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 0\n",
      "Leak values found in train 299\n",
      "% of correct leaks values in train  0.979933110367893\n",
      "Score (filled with nonzero mean) 1.5138333391635181\n",
      "Processing lag 1\n",
      "Leak values found in train 446\n",
      "% of correct leaks values in train  0.984304932735426\n",
      "Score (filled with nonzero mean) 1.4772272652360527\n",
      "Processing lag 2\n",
      "Leak values found in train 565\n",
      "% of correct leaks values in train  0.9787610619469026\n",
      "Score (filled with nonzero mean) 1.4609901689108993\n",
      "Processing lag 3\n",
      "Leak values found in train 629\n",
      "% of correct leaks values in train  0.9809220985691574\n",
      "Score (filled with nonzero mean) 1.4467458096662653\n",
      "Processing lag 4\n",
      "Leak values found in train 670\n",
      "% of correct leaks values in train  0.9791044776119403\n",
      "Score (filled with nonzero mean) 1.4369522015753753\n",
      "Processing lag 5\n",
      "Leak values found in train 705\n",
      "% of correct leaks values in train  0.9773049645390071\n",
      "Score (filled with nonzero mean) 1.429888414041253\n",
      "Processing lag 6\n",
      "Leak values found in train 735\n",
      "% of correct leaks values in train  0.9741496598639455\n",
      "Score (filled with nonzero mean) 1.4245689769115608\n",
      "Processing lag 7\n",
      "Leak values found in train 772\n",
      "% of correct leaks values in train  0.9740932642487047\n",
      "Score (filled with nonzero mean) 1.419439049335751\n",
      "Processing lag 8\n",
      "Leak values found in train 799\n",
      "% of correct leaks values in train  0.9737171464330413\n",
      "Score (filled with nonzero mean) 1.4129624109129981\n",
      "Processing lag 9\n",
      "Leak values found in train 812\n",
      "% of correct leaks values in train  0.9741379310344828\n",
      "Score (filled with nonzero mean) 1.4101793198562746\n",
      "Processing lag 10\n",
      "Leak values found in train 832\n",
      "% of correct leaks values in train  0.9735576923076923\n",
      "Score (filled with nonzero mean) 1.4070778147675054\n",
      "Processing lag 11\n",
      "Leak values found in train 842\n",
      "% of correct leaks values in train  0.9738717339667459\n",
      "Score (filled with nonzero mean) 1.4051306126616818\n",
      "Processing lag 12\n",
      "Leak values found in train 861\n",
      "% of correct leaks values in train  0.967479674796748\n",
      "Score (filled with nonzero mean) 1.4047724128738068\n",
      "Processing lag 13\n",
      "Leak values found in train 873\n",
      "% of correct leaks values in train  0.9679266895761741\n",
      "Score (filled with nonzero mean) 1.4028496314610814\n",
      "Processing lag 14\n",
      "Leak values found in train 886\n",
      "% of correct leaks values in train  0.9683972911963883\n",
      "Score (filled with nonzero mean) 1.3995573170016826\n",
      "Processing lag 15\n",
      "Leak values found in train 892\n",
      "% of correct leaks values in train  0.968609865470852\n",
      "Score (filled with nonzero mean) 1.3973821458615512\n",
      "Processing lag 16\n",
      "Leak values found in train 899\n",
      "% of correct leaks values in train  0.9688542825361512\n",
      "Score (filled with nonzero mean) 1.3949392684566084\n",
      "Processing lag 17\n",
      "Leak values found in train 902\n",
      "% of correct leaks values in train  0.9689578713968958\n",
      "Score (filled with nonzero mean) 1.3934242508969383\n",
      "Processing lag 18\n",
      "Leak values found in train 908\n",
      "% of correct leaks values in train  0.9680616740088106\n",
      "Score (filled with nonzero mean) 1.3927254645659817\n",
      "Processing lag 19\n",
      "Leak values found in train 912\n",
      "% of correct leaks values in train  0.9671052631578947\n",
      "Score (filled with nonzero mean) 1.3911597773069089\n",
      "Processing lag 20\n",
      "Leak values found in train 912\n",
      "% of correct leaks values in train  0.9671052631578947\n",
      "Score (filled with nonzero mean) 1.3908429766310588\n",
      "Processing lag 21\n",
      "Leak values found in train 919\n",
      "% of correct leaks values in train  0.9662676822633297\n",
      "Score (filled with nonzero mean) 1.3908429766310588\n",
      "Processing lag 22\n",
      "Leak values found in train 922\n",
      "% of correct leaks values in train  0.96529284164859\n",
      "Score (filled with nonzero mean) 1.3910675663136076\n",
      "Processing lag 23\n",
      "Leak values found in train 924\n",
      "% of correct leaks values in train  0.9653679653679653\n",
      "Score (filled with nonzero mean) 1.3908173548184746\n",
      "Processing lag 24\n",
      "Leak values found in train 926\n",
      "% of correct leaks values in train  0.9654427645788337\n",
      "Score (filled with nonzero mean) 1.3902700012630624\n",
      "Processing lag 25\n",
      "Leak values found in train 927\n",
      "% of correct leaks values in train  0.9654800431499461\n",
      "Score (filled with nonzero mean) 1.3902488114997713\n",
      "Processing lag 26\n",
      "Leak values found in train 930\n",
      "% of correct leaks values in train  0.964516129032258\n",
      "Score (filled with nonzero mean) 1.3902445653393045\n",
      "Processing lag 27\n",
      "Leak values found in train 931\n",
      "% of correct leaks values in train  0.9645542427497314\n",
      "Score (filled with nonzero mean) 1.3900973566401726\n",
      "Processing lag 28\n",
      "Leak values found in train 932\n",
      "% of correct leaks values in train  0.9635193133047211\n",
      "Score (filled with nonzero mean) 1.3900973566401726\n",
      "Processing lag 29\n",
      "Leak values found in train 932\n",
      "% of correct leaks values in train  0.9635193133047211\n",
      "Score (filled with nonzero mean) 1.3910831191583384\n",
      "Processing lag 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "KeyboardInterrupt                         Traceback (most recent call last)",
      "<ipython-input-39-94cbd2013024> in <module>()\n----> 1 train_leak, result = compiled_leak_result()\n",
      "<ipython-input-34-fb7989bfa005> in compiled_leak_result()\n     17         \n     18         print('Processing lag', i)\n---> 19         train_leak[c] = _get_leak(train_leak, cols, i)\n     20         \n     21         leaky_cols.append(c)\n",
      "<ipython-input-33-ecf7c360a77c> in _get_leak(df, cols, lag)\n      2 def _get_leak(df, cols, lag=0):\n      3     d1 = df[cols[:-lag-2]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n----> 4     d2 = df[cols[lag+2:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n      5     d2['pred'] = df[cols[lag]]\n      6     #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/frame.py in apply(self, func, axis, broadcast, raw, reduce, args, **kwds)\n   4875                         f, axis,\n   4876                         reduce=reduce,\n-> 4877                         ignore_failures=ignore_failures)\n   4878             else:\n   4879                 return self._apply_broadcast(f, axis)\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/frame.py in _apply_standard(self, func, axis, ignore_failures, reduce)\n   4931                     labels = self._get_agg_axis(axis)\n   4932                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n-> 4933                                         labels=labels)\n   4934                     return Series(result, index=labels)\n   4935                 except Exception:\n",
      "pandas/_libs/src/reduce.pyx in pandas._libs.lib.reduce()\n",
      "pandas/_libs/src/reduce.pyx in pandas._libs.lib.Reducer.get_result()\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/base.py in __iter__(self)\n    823         (for Timestamp/Timedelta/Interval/Period)\n    824         \"\"\"\n--> 825         return iter(self.tolist())\n    826 \n    827     @cache_readonly\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/base.py in tolist(self)\n    810         \"\"\"\n    811 \n--> 812         if is_datetimelike(self):\n    813             return [_maybe_box_datetimelike(x) for x in self._values]\n    814         else:\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/dtypes/common.py in is_datetimelike(arr)\n    649     \"\"\"\n    650 \n--> 651     return (is_datetime64_dtype(arr) or is_datetime64tz_dtype(arr) or\n    652             is_timedelta64_dtype(arr) or\n    653             isinstance(arr, ABCPeriodIndex) or\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/dtypes/common.py in is_datetime64tz_dtype(arr_or_dtype)\n    367     if arr_or_dtype is None:\n    368         return False\n--> 369     return DatetimeTZDtype.is_dtype(arr_or_dtype)\n    370 \n    371 \n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/dtypes/dtypes.py in is_dtype(cls, dtype)\n     88         we can match (via string or type)\n     89         \"\"\"\n---> 90         if hasattr(dtype, 'dtype'):\n     91             dtype = dtype.dtype\n     92         if isinstance(dtype, np.dtype):\n",
      "~/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/pandas/core/series.py in dtype(self)\n    348     def dtype(self):\n    349         \"\"\" return the dtype object of the underlying data \"\"\"\n--> 350         return self._data.dtype\n    351 \n    352     @property\n",
      "KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "train_leak, result = compiled_leak_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d904afe6c581aa250592432402977b1ab2b3ede",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(result, orient='columns')\n",
    "result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "629ec0c6ee122fd82bf40f09a55a3f6f8f6c7fdf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('train_leaky_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42bfb7c9b41f687c189229f83cc6c8c7fd100536",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_leak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15e49a1e6f3d95150a4114edca7d3ae910bc6ee3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = np.min(result['score'])\n",
    "best_lag = np.argmin(result['score'])\n",
    "print('best_score', best_score, '\\nbest_lag', best_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9dd516686724d756329a5f42c7c53b688c55aceb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rewrite_compiled_leak(leak_df, lag):\n",
    "    leak_df[\"compiled_leak\"] = 0\n",
    "    for i in range(lag):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        zeroleak = leak_df[\"compiled_leak\"]==0\n",
    "        leak_df.loc[zeroleak, \"compiled_leak\"] = leak_df.loc[zeroleak, c]\n",
    "    return leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4982c4cd26a0c84ec34402fd7816f49c630e191",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaky_cols = [c for c in train_leak.columns if 'leaked_target_' in c]\n",
    "train_leak = rewrite_compiled_leak(train_leak, best_lag)\n",
    "train_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8902d9458668d79eef27c6761a3c6fd43578824",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_res = train_leak[leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "train_res.to_csv('train_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ce80d9f0bf6a44471921328a6fd2c274821485d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compiled_leak_result_test(max_nlags):\n",
    "    test_leak = test[[\"ID\", \"target\"] + cols]\n",
    "    test_leak[\"compiled_leak\"] = 0\n",
    "    test_leak[\"nonzero_mean\"] = test[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    # leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        test_leak[c] = _get_leak(test_leak, cols, i)\n",
    "        \n",
    "        leaky_cols.append(c)\n",
    "        test_leak = test.join(\n",
    "            test_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )[[\"ID\", \"target\"] + cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]\n",
    "        zeroleak = test_leak[\"compiled_leak\"]==0\n",
    "        test_leak.loc[zeroleak, \"compiled_leak\"] = test_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(test_leak[\"compiled_leak\"] > 0))\n",
    "        #_correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        #leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in test\", leaky_value_counts[-1])\n",
    "        #print(\n",
    "        #    \"% of correct leaks values in train \", \n",
    "        #    leaky_value_corrects[-1]\n",
    "        #)\n",
    "        #tmp = train_leak.copy()\n",
    "        #tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n",
    "        #scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        #print(\n",
    "        #    'Score (filled with nonzero mean)', \n",
    "        #    scores[-1]\n",
    "        #)\n",
    "    result = dict(\n",
    "        # score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        # leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return test_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "a85699f8864b93664abde5b893426f94583bb7ab",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_leak, test_result = compiled_leak_result_test(max_nlags=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f581e7e9f6a68169f2897e44ba9e8919ac6241c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result = pd.DataFrame.from_dict(test_result, orient='columns')\n",
    "test_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3559543eccb2c35ae6f06a842f67f9aa54fa264d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result.to_csv('test_leaky_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06015b64764b4998669bb7fef877bb781b3ebc1a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_leak = rewrite_compiled_leak(test_leak, best_lag)\n",
    "test_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebca69ea7200a5245e8feeab4cb0b20a2606fb27",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_res = test_leak[leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "test_res.to_csv('test_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f92ce5d52d5d2676adba8412d8ca8ce9983761e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_leak.loc[test_leak[\"compiled_leak\"]==0, \"compiled_leak\"] = test_leak.loc[test_leak[\"compiled_leak\"]==0, \"nonzero_mean\"]\n",
    "test_leak.loc[test_leak[\"compiled_leak\"]==0, \"compiled_leak\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc2e522df90f97456e67f26977fde364acf02876",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "sub = test[[\"ID\"]]\n",
    "sub[\"target\"] = test_leak[\"compiled_leak\"]\n",
    "sub.to_csv(f\"baseline_sub_lag_{best_lag}.csv\", index=False)\n",
    "print(f\"baseline_sub_lag_{best_lag}.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f8fa3cbae8cb81a1911983877e2a9aeda9c3bff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f958838c19da7ed87e9a3529cb5fce2205e46ff2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
