{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56f3c3499260fe04c9d0c6535f59ea3320b8c987",
    "collapsed": true
   },
   "source": [
    "> Please go through Giba's post and kernel  to underrstand what this leak is all about\n",
    "> https://www.kaggle.com/titericz/the-property-by-giba (kernel)\n",
    "> https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post)\n",
    "> \n",
    "> Also, go through this Jiazhen's kernel which finds more columns to exploit leak\n",
    "> https://www.kaggle.com/johnfarrell/giba-s-property-extended-result\n",
    "> \n",
    "> I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field.\n",
    "> \n",
    "> **Let the competition begin! :D**\n",
    "\n",
    "### Just some small modifications from [original baseline](https://www.kaggle.com/tezdhar/breaking-lb-fresh-start)~\n",
    "- The leak rows are calculated separately on train/test set\n",
    "- Calculated the leaky values, correctness, for each lag\n",
    "- Hope this can help to do some *lag_selection*\n",
    "\n",
    "### Update leak process codes to Dmitry Frumkin's *fast* [version](https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2)\n",
    "- The result of Dmitry's original function and result of Hasan's function seem slightly different\n",
    "- Modified to make the output consistent with Hasan's function (Seems better score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "dc37a766646b5993cef0bc87ad6882728dd20cb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "transact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\n",
    "y = np.log1p(train[\"target\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9951f375af0d5a753031352e04a85a5a12a93e18",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"target\"] = train[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6dcfc4df1340c38bfeac43fd4d19ba2763b3b916"
   },
   "source": [
    "We take time series columns from [here](https://www.kaggle.com/johnfarrell/giba-s-property-extended-result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', \n",
    "        'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', \n",
    "        '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867', \n",
    "        'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', \n",
    "        '1931ccfdd', '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', \n",
    "        '6619d81fc', '1db387535', \n",
    "        'fc99f9426',\n",
    "        '91f701ba2', '0572565c2', '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98'\n",
    "       ]\n",
    "\n",
    "extra_feats = [['ced6a7e91','9df4daa99','83c3779bf','edc84139a','f1e0ada11','73687e512',\n",
    "                'aa164b93b','342e7eb03','cd24eae8a','8f3740670','2b2a10857','a00adf70e',\n",
    "                '3a48a2cd2','a396ceeb9','9280f3d04','fec5eaf1a','5b943716b','22ed6dba3',\n",
    "                '5547d6e11','e222309b0','5d3b81ef8','1184df5c2','2288333b4','f39074b55',\n",
    "                'a8b721722','13ee58af1','fb387ea33','4da206d28','ea4046b8d','ef30f6be5',\n",
    "                'b85fa8b27','2155f5e16']]\n",
    "# extra_feats = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2664b88d70c76fde0df57ca6f22f75997f72cb00",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2\n",
    "def _get_leak(df, cols, extra_feats=[[]], lag=0):\n",
    "    f1 = cols[:-lag-2]\n",
    "    f2 = cols[lag+2:]\n",
    "    for ef in extra_feats:\n",
    "        f1 += ef[:-lag-2]\n",
    "        f2 += ef[lag+2:]\n",
    "    \n",
    "    d1 = df[f1].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2 = df[f2].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2['pred'] = df[cols[lag]]\n",
    "    #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n",
    "    d3 = d2[~d2.duplicated(['key'], keep=False)]\n",
    "    return d1.merge(d3, how='left', on='key').pred.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "d61c75092518f50a879e9e3d5883ab752f73912b"
   },
   "outputs": [],
   "source": [
    "def compiled_leak_result():\n",
    "    \n",
    "    max_nlags = len(cols) - 2\n",
    "#     train_leak = train[[\"ID\", \"target\"] + cols]\n",
    "    train_leak = train\n",
    "    train_leak[\"compiled_leak\"] = 0\n",
    "    train_leak[\"nonzero_mean\"] = train[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        train_leak[c] = _get_leak(train_leak, cols, extra_feats, i)\n",
    "        \n",
    "        leaky_cols.append(c)\n",
    "#         train_leak = train.join(train_leak[leaky_cols+[\"compiled_leak\", \"nonzero_mean\", \"ID\"]], on='ID', how='left')\n",
    "        zeroleak = train_leak[\"compiled_leak\"]==0\n",
    "        train_leak.loc[zeroleak, \"compiled_leak\"] = train_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(train_leak[\"compiled_leak\"] > 0))\n",
    "        _correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in train\", leaky_value_counts[-1])\n",
    "        print(\n",
    "            \"% of correct leaks values in train \", \n",
    "            leaky_value_corrects[-1]\n",
    "        )\n",
    "        tmp = train_leak.copy()\n",
    "        tmp.loc[zeroleak, \"compiled_leak\"] = train_leak[\"nonzero_mean\"]\n",
    "        scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        print(\n",
    "            'Score (filled with nonzero mean)', \n",
    "            scores[-1]\n",
    "        )\n",
    "    result = dict(\n",
    "        score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return train_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "68f3fde6e5e9d274a4de6ef0975bbb4b682d5e85",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 0\n",
      "Leak values found in train 1373\n",
      "% of correct leaks values in train  0.997086671522\n",
      "Score (filled with nonzero mean) 1.51383333916\n",
      "Processing lag 1\n",
      "Leak values found in train 1974\n",
      "% of correct leaks values in train  0.997973657548\n",
      "Score (filled with nonzero mean) 1.28791574401\n",
      "Processing lag 2\n",
      "Leak values found in train 2363\n",
      "% of correct leaks values in train  0.997884045705\n",
      "Score (filled with nonzero mean) 1.1669163053\n",
      "Processing lag 3\n",
      "Leak values found in train 2605\n",
      "% of correct leaks values in train  0.998080614203\n",
      "Score (filled with nonzero mean) 1.07254507963\n",
      "Processing lag 4\n",
      "Leak values found in train 2773\n",
      "% of correct leaks values in train  0.998196898666\n",
      "Score (filled with nonzero mean) 1.01970025095\n",
      "Processing lag 5\n",
      "Leak values found in train 2920\n",
      "% of correct leaks values in train  0.997945205479\n",
      "Score (filled with nonzero mean) 0.980080548442\n",
      "Processing lag 6\n",
      "Leak values found in train 3042\n",
      "% of correct leaks values in train  0.997041420118\n",
      "Score (filled with nonzero mean) 0.933771811466\n",
      "Processing lag 7\n",
      "Leak values found in train 3148\n",
      "% of correct leaks values in train  0.995870393901\n",
      "Score (filled with nonzero mean) 0.886911704392\n",
      "Processing lag 8\n",
      "Leak values found in train 3229\n",
      "% of correct leaks values in train  0.995973985754\n",
      "Score (filled with nonzero mean) 0.858221310667\n",
      "Processing lag 9\n",
      "Leak values found in train 3282\n",
      "% of correct leaks values in train  0.995734308349\n",
      "Score (filled with nonzero mean) 0.837999249898\n",
      "Processing lag 10\n",
      "Leak values found in train 3340\n",
      "% of correct leaks values in train  0.995808383234\n",
      "Score (filled with nonzero mean) 0.824176934583\n",
      "Processing lag 11\n",
      "Leak values found in train 3381\n",
      "% of correct leaks values in train  0.995859213251\n",
      "Score (filled with nonzero mean) 0.809437445913\n",
      "Processing lag 12\n",
      "Leak values found in train 3428\n",
      "% of correct leaks values in train  0.99504084014\n",
      "Score (filled with nonzero mean) 0.793021132405\n",
      "Processing lag 13\n",
      "Leak values found in train 3467\n",
      "% of correct leaks values in train  0.995096625324\n",
      "Score (filled with nonzero mean) 0.779180259036\n",
      "Processing lag 14\n",
      "Leak values found in train 3504\n",
      "% of correct leaks values in train  0.994577625571\n",
      "Score (filled with nonzero mean) 0.765855882278\n",
      "Processing lag 15\n",
      "Leak values found in train 3526\n",
      "% of correct leaks values in train  0.994611457742\n",
      "Score (filled with nonzero mean) 0.75685743565\n",
      "Processing lag 16\n",
      "Leak values found in train 3545\n",
      "% of correct leaks values in train  0.994358251058\n",
      "Score (filled with nonzero mean) 0.751954632885\n",
      "Processing lag 17\n",
      "Leak values found in train 3568\n",
      "% of correct leaks values in train  0.994394618834\n",
      "Score (filled with nonzero mean) 0.74459277267\n",
      "Processing lag 18\n",
      "Leak values found in train 3585\n",
      "% of correct leaks values in train  0.994421199442\n",
      "Score (filled with nonzero mean) 0.737323998487\n",
      "Processing lag 19\n",
      "Leak values found in train 3602\n",
      "% of correct leaks values in train  0.99444752915\n",
      "Score (filled with nonzero mean) 0.73208269186\n",
      "Processing lag 20\n",
      "Leak values found in train 3615\n",
      "% of correct leaks values in train  0.994467496542\n",
      "Score (filled with nonzero mean) 0.722934114924\n",
      "Processing lag 21\n",
      "Leak values found in train 3629\n",
      "% of correct leaks values in train  0.994488839901\n",
      "Score (filled with nonzero mean) 0.713148689996\n",
      "Processing lag 22\n",
      "Leak values found in train 3643\n",
      "% of correct leaks values in train  0.993686522097\n",
      "Score (filled with nonzero mean) 0.704928473807\n",
      "Processing lag 23\n",
      "Leak values found in train 3659\n",
      "% of correct leaks values in train  0.993167532113\n",
      "Score (filled with nonzero mean) 0.703484213728\n",
      "Processing lag 24\n",
      "Leak values found in train 3673\n",
      "% of correct leaks values in train  0.991832289681\n",
      "Score (filled with nonzero mean) 0.697212780429\n",
      "Processing lag 25\n",
      "Leak values found in train 3680\n",
      "% of correct leaks values in train  0.991847826087\n",
      "Score (filled with nonzero mean) 0.706753195023\n",
      "Processing lag 26\n",
      "Leak values found in train 3690\n",
      "% of correct leaks values in train  0.991327913279\n",
      "Score (filled with nonzero mean) 0.704717742322\n",
      "Processing lag 27\n",
      "Leak values found in train 3694\n",
      "% of correct leaks values in train  0.991337303736\n",
      "Score (filled with nonzero mean) 0.702495867248\n",
      "Processing lag 28\n",
      "Leak values found in train 3700\n",
      "% of correct leaks values in train  0.991081081081\n",
      "Score (filled with nonzero mean) 0.70080883713\n",
      "Processing lag 29\n",
      "Leak values found in train 3704\n",
      "% of correct leaks values in train  0.990280777538\n",
      "Score (filled with nonzero mean) 0.700161215427\n",
      "Processing lag 30\n",
      "Leak values found in train 3712\n",
      "% of correct leaks values in train  0.988685344828\n",
      "Score (filled with nonzero mean) 0.702519272875\n",
      "Processing lag 31\n",
      "Leak values found in train 3715\n",
      "% of correct leaks values in train  0.987886944818\n",
      "Score (filled with nonzero mean) 0.702288501521\n",
      "Processing lag 32\n",
      "Leak values found in train 3718\n",
      "% of correct leaks values in train  0.987089833244\n",
      "Score (filled with nonzero mean) 0.702821423315\n",
      "Processing lag 33\n",
      "Leak values found in train 3728\n",
      "% of correct leaks values in train  0.984978540773\n",
      "Score (filled with nonzero mean) 0.703772326865\n",
      "Processing lag 34\n",
      "Leak values found in train 3730\n",
      "% of correct leaks values in train  0.98471849866\n",
      "Score (filled with nonzero mean) 0.703403154159\n",
      "Processing lag 35\n",
      "Leak values found in train 3731\n",
      "% of correct leaks values in train  0.98445456982\n",
      "Score (filled with nonzero mean) 0.703953883689\n",
      "Processing lag 36\n",
      "Leak values found in train 3734\n",
      "% of correct leaks values in train  0.983663631494\n",
      "Score (filled with nonzero mean) 0.706946683617\n",
      "Processing lag 37\n",
      "Leak values found in train 3734\n",
      "% of correct leaks values in train  0.983663631494\n",
      "Score (filled with nonzero mean) 0.706404547901\n"
     ]
    }
   ],
   "source": [
    "train_leak, result = compiled_leak_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d904afe6c581aa250592432402977b1ab2b3ede",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(result, orient='columns')\n",
    "result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "629ec0c6ee122fd82bf40f09a55a3f6f8f6c7fdf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('train_leaky_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42bfb7c9b41f687c189229f83cc6c8c7fd100536",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_leak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15e49a1e6f3d95150a4114edca7d3ae910bc6ee3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = np.min(result['score'])\n",
    "best_lag = np.argmin(result['score'])\n",
    "print('best_score', best_score, '\\nbest_lag', best_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9dd516686724d756329a5f42c7c53b688c55aceb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rewrite_compiled_leak(leak_df, lag):\n",
    "    leak_df[\"compiled_leak\"] = 0\n",
    "    for i in range(lag):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        zeroleak = leak_df[\"compiled_leak\"]==0\n",
    "        leak_df.loc[zeroleak, \"compiled_leak\"] = leak_df.loc[zeroleak, c]\n",
    "    return leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4982c4cd26a0c84ec34402fd7816f49c630e191",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaky_cols = [c for c in train_leak.columns if 'leaked_target_' in c]\n",
    "train_leak = rewrite_compiled_leak(train_leak, best_lag)\n",
    "train_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8902d9458668d79eef27c6761a3c6fd43578824",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_res = train_leak[leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "train_res.to_csv('train_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ce80d9f0bf6a44471921328a6fd2c274821485d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compiled_leak_result_test(max_nlags):\n",
    "    test_leak = test[[\"ID\", \"target\"] + cols]\n",
    "    test_leak[\"compiled_leak\"] = 0\n",
    "    test_leak[\"nonzero_mean\"] = test[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    # leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        test_leak[c] = _get_leak(test_leak, cols, i)\n",
    "        \n",
    "        leaky_cols.append(c)\n",
    "        test_leak = test.join(\n",
    "            test_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )[[\"ID\", \"target\"] + cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]\n",
    "        zeroleak = test_leak[\"compiled_leak\"]==0\n",
    "        test_leak.loc[zeroleak, \"compiled_leak\"] = test_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(test_leak[\"compiled_leak\"] > 0))\n",
    "        #_correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        #leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in test\", leaky_value_counts[-1])\n",
    "        #print(\n",
    "        #    \"% of correct leaks values in train \", \n",
    "        #    leaky_value_corrects[-1]\n",
    "        #)\n",
    "        #tmp = train_leak.copy()\n",
    "        #tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n",
    "        #scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        #print(\n",
    "        #    'Score (filled with nonzero mean)', \n",
    "        #    scores[-1]\n",
    "        #)\n",
    "    result = dict(\n",
    "        # score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        # leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return test_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "a85699f8864b93664abde5b893426f94583bb7ab",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_leak, test_result = compiled_leak_result_test(max_nlags=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f581e7e9f6a68169f2897e44ba9e8919ac6241c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result = pd.DataFrame.from_dict(test_result, orient='columns')\n",
    "test_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3559543eccb2c35ae6f06a842f67f9aa54fa264d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result.to_csv('test_leaky_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06015b64764b4998669bb7fef877bb781b3ebc1a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_leak = rewrite_compiled_leak(test_leak, best_lag)\n",
    "test_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebca69ea7200a5245e8feeab4cb0b20a2606fb27",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_res = test_leak[leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "test_res.to_csv('test_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f92ce5d52d5d2676adba8412d8ca8ce9983761e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_leak.loc[test_leak[\"compiled_leak\"]==0, \"compiled_leak\"] = test_leak.loc[test_leak[\"compiled_leak\"]==0, \"nonzero_mean\"]\n",
    "test_leak.loc[test_leak[\"compiled_leak\"]==0, \"compiled_leak\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc2e522df90f97456e67f26977fde364acf02876",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "sub = test[[\"ID\"]]\n",
    "sub[\"target\"] = test_leak[\"compiled_leak\"]\n",
    "sub.to_csv(f\"baseline_sub_lag_{best_lag}.csv\", index=False)\n",
    "print(f\"baseline_sub_lag_{best_lag}.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f8fa3cbae8cb81a1911983877e2a9aeda9c3bff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f958838c19da7ed87e9a3529cb5fce2205e46ff2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
